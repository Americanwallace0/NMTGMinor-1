import numpy as np
import torch, math
import torch.nn as nn
import torch.nn.functional as F
from onmt.modules.Transformer.Layers import PositionalEncoding
from onmt.modules.Transformer.Layers import EncoderLayer, DecoderLayer
from onmt.modules.StochasticTransformer.Layers import StochasticEncoderLayer, StochasticDecoderLayer
from onmt.modules.Transformer.Models import TransformerEncoder, TransformerDecoder
import onmt
from onmt.modules.WordDrop import embedded_dropout
from onmt.modules.Transformer.Layers import XavierLinear, MultiHeadAttention, FeedForward, PrePostProcessing
Linear = XavierLinear

import copy
"""
    Variational Inference for model depth generation

    Our model structure is generated by a latent variable z = {z_1, z_2 .... z_n} corresponding to n layers
    Assumption is each layer is generated randomly (motivated by the Stochastic Network)
    Mean Field assumption is used (one set of parameters for each z)

    Our loss function is:

    L = E_q_z ( log (p (Y|X, z)) - KL( q(z|X, y) || p(z|X))
    (data likelihood given the latent variable)
    
    The Prior model estimates p(z | x)

    The Posterior model estimates q(z | x, y)

    During training we take the sample from posterior (variational inference)
    During testing  y is not available, so we use the prior (conditional prior)

"""

def mean_with_mask(context, mask):

    # context dimensions: T x B x H
    # mask dimension: T x B x 1 (with unsqueeze)
    # first, we have to mask the context with zeros at the unwanted position

    context.masked_fill_(mask, 0)

    # then take the sum over the dimension
    context_sum = torch.sum(context, dim=0, keepdim=False)


    weights = torch.sum(1 - mask, dim=0, keepdim=False).type_as(context_sum)

    mean = context_sum.div_(weights)

    return mean

"""
    The Prior model estimates p(z | x)


"""
class NeuralPrior(nn.Module):

    """Encoder in 'Attention is all you need'
    
    Args:
        opt: list of options ( see train.py )
        dicts : dictionary (for source language)
        
    """
    def __init__(self, opt, dicts, positional_encoder):
    
        super(NeuralPrior, self).__init__()

        encoder_opt = copy.deepcopy(opt)
        # quick_hack to override some hyper parameters of the prior encoder
        # encoder_opt.layers = 
        #  encoder_opt.word_dropout = 0.0 
        self.dropout = opt.dropout
        self.n_layers = opt.layers

        self.projector = Linear(opt.model_size, opt.model_size)
        self.predictor = Linear(opt.model_size, opt.layers * 2)
        # self.mean_predictor = Linear(opt.model_size, opt.model_size)
        # self.var_predictor = Linear(opt.model_size, opt.model_size)
# 
    def forward(self, encoder_context, input, **kwargs):
        """
        Inputs Shapes: 
            input: batch_size x len_src (wanna tranpose)
        
        Outputs Shapes:
            out: batch_size x len_src x d_model
            mask_src 
            
        """
        # pass the input to the transformer encoder
        context = encoder_context
          
        # Now we have to mask the context with zeros
        # context size: T x B x H
        mask = input.eq(onmt.Constants.PAD).transpose(0, 1).unsqueeze(2)

        # context.masked_fill_(mask, 0)
        context = mean_with_mask(context, mask)
        

        context = torch.tanh(self.projector(context))       
        layer_probs = self.predictor(context)

        layer_probs = layer_probs.view(-1, self.n_layers, 2)

        layer_probs = F.softmax(layer_probs.float(), dim=-1)
        # mean = self.mean_predictor(context)       
        # var = torch.nn.functional.softplus(self.var_predictor(context))

        # p_z = torch.distributions.bernoulli.Bernoulli(layer_probs.float())
        p_z = torch.distributions.categorical.Categorical(probs=layer_probs)
        # print(p_z.probs.size())

        # return prior distribution P(z | X)
        return p_z


class NeuralPosterior(nn.Module):

    """Neural Posterior using Transformer
    
    Args:
        opt: list of options ( see train.py )
        dicts : dictionary (for source language)
        
    """
    
    def __init__(self, opt, dicts, positional_encoder):
    
        super(NeuralPosterior, self).__init__()
        
        encoder_opt = copy.deepcopy(opt)

        # quick_hack to override some hyper parameters of the prior encoder
        # encoder_opt.layers = 4
        encoder_opt.word_dropout = 0.0 
        encoder_opt.dropout = 0.0
        self.dropout = opt.dropout
        self.projector = Linear(opt.model_size * 2, opt.model_size)
        self.encoder = TransformerEncoder(encoder_opt, dicts, positional_encoder)
        self.predictor = Linear(opt.model_size, opt.layers * 2)
        self.n_layers = opt.layers
        # self.mean_predictor = Linear(opt.model_size, opt.model_size)
        # self.var_predictor = Linear(opt.model_size, opt.model_size)
    
    def forward(self, encoder_context, input_src, input_tgt, **kwargs):
        """
        Inputs Shapes: 
            input: batch_size x len_src (wanna tranpose)
        
        Outputs Shapes:
            out: batch_size x len_src x d_model
            mask_src 
            
        """

        """ Embedding: batch_size x len_src x d_model """
       
        decoder_context, _ = self.encoder(input_tgt, **kwargs)

        src_mask = input_src.eq(onmt.Constants.PAD).transpose(0, 1).unsqueeze(2)
        tgt_mask = input_tgt.eq(onmt.Constants.PAD).transpose(0, 1).unsqueeze(2)


        # take the mean of each context
        encoder_context = mean_with_mask(encoder_context, src_mask)
        decoder_context = mean_with_mask(decoder_context, tgt_mask)

        context = torch.cat([encoder_context, decoder_context], dim=-1)

        context = torch.tanh(self.projector(context))
        
        # layer_probs = torch.sigmoid(self.predictor(context))
        layer_probs = self.predictor(context)
        layer_probs = layer_probs.view(-1, self.n_layers, 2)

        layer_probs = F.softmax(layer_probs.float(), dim=-1)

        q_z = torch.distributions.categorical.Categorical(probs=layer_probs)
        
        return q_z




class Baseline(nn.Module):

    """Neural Posterior using Transformer
    
    Args:
        opt: list of options ( see train.py )
        dicts : dictionary (for source language)
        
    """
    
    def __init__(self, opt, dicts, positional_encoder):
    
        super(Baseline, self).__init__()
        
        encoder_opt = copy.deepcopy(opt)

        # quick_hack to override some hyper parameters of the prior encoder
        # encoder_opt.layers = 4
        encoder_opt.word_dropout = 0.0 
        encoder_opt.dropout = 0.0
        self.dropout = opt.dropout
        self.projector = Linear(opt.model_size * 2, opt.model_size)
        self.encoder = TransformerEncoder(encoder_opt, dicts, positional_encoder)
        self.predictor = Linear(opt.model_size, 1)
        # self.mean_predictor = Linear(opt.model_size, opt.model_size)
        # self.var_predictor = Linear(opt.model_size, opt.model_size)
    
    def forward(self, encoder_context, input_src, input_tgt, **kwargs):
        """
        Inputs Shapes: 
            input: batch_size x len_src (wanna tranpose)
        
        Outputs Shapes:
            out: batch_size x len_src x d_model
            mask_src 
            
        """

        """ Embedding: batch_size x len_src x d_model """
       
        decoder_context, _ = self.encoder(input_tgt, **kwargs)

        src_mask = input_src.eq(onmt.Constants.PAD).transpose(0, 1).unsqueeze(2)
        tgt_mask = input_tgt.eq(onmt.Constants.PAD).transpose(0, 1).unsqueeze(2)


        # take the mean of each context
        encoder_context = encoder_context.detach()
        encoder_context = mean_with_mask(encoder_context, src_mask)
        decoder_context = mean_with_mask(decoder_context, tgt_mask)

        context = torch.cat([encoder_context, decoder_context], dim=-1)
        # context = F.dropout(context, training=self.training, p=self.dropout)

        context = torch.tanh(self.projector(context))

        b = self.predictor(context)
        
        
        return b



class RecurrentNeuralPosterior(nn.Module):

    """Neural Posterior using Transformer
    
    Args:
        opt: list of options ( see train.py )
        dicts : dictionary (for source language)
        
    """
    
    def __init__(self, opt, dicts, positional_encoder):
    
        super(NeuralPosterior, self).__init__()
        
        encoder_opt = copy.deepcopy(opt)

        # quick_hack to override some hyper parameters of the prior encoder
        # encoder_opt.layers = 4
        # encoder_opt.word_dropout = 0.0 
        self.dropout = opt.dropout
        self.projector = Linear(opt.model_size * 2, opt.model_size)
        self.encoder = TransformerEncoder(encoder_opt, dicts, positional_encoder)
        self.predictor = Linear(opt.model_size, 2)
        self.mapper = Linear(opt.model_size, opt.model_size)
        self.n_steps = opt.layers
        # self.mean_predictor = Linear(opt.model_size, opt.model_size)
        # self.var_predictor = Linear(opt.model_size, opt.model_size)
    
    def forward(self, encoder_context, input_src, input_tgt, **kwargs):
        """
        Inputs Shapes: 
            input: batch_size x len_src (wanna tranpose)
        
        Outputs Shapes:
            out: batch_size x len_src x d_model
            mask_src 
            
        """

        """ Embedding: batch_size x len_src x d_model """
       
        decoder_context, _ = self.encoder(input_tgt, **kwargs)

        src_mask = input_src.eq(onmt.Constants.PAD).transpose(0, 1).unsqueeze(2)
        tgt_mask = input_tgt.eq(onmt.Constants.PAD).transpose(0, 1).unsqueeze(2)


        # take the mean of each context
        encoder_context = mean_with_mask(encoder_context, src_mask)
        decoder_context = mean_with_mask(decoder_context, tgt_mask)

        context = torch.cat([encoder_context, decoder_context], dim=-1)

        context = torch.tanh(self.projector(context))
        
        layer_probs = torch.sigmoid(self.predictor(context))
        # print(layer_probs.size())
        # var = torch.nn.functional.softplus(self.var_predictor(context))

        q_z = torch.distributions.bernoulli.Bernoulli(layer_probs.float())
        # return distribution Q(z | X, Y)
        return q_z